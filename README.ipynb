{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This repository shows the implementation of a **Custom Environment** in [GYM](https://gym.openai.com/) using [Stable Baselines](https://stable-baselines.readthedocs.io/en/master/index.html).\n",
    "\n",
    "\n",
    "In Detail: This Repository is a [GYM](https://gym.openai.com/) Implementation for [Gearbox](https://github.com/HoChiak/Gearbox/). The Gearbox-RePo simulates the vibration behaviour of a gearbox under degradation. In terms of Reinforcement Learning the goal is to decrease the degradation to a minimum. Actions are taken by applying an adapted torque input strategy.\n",
    "\n",
    "Further Aspects of this Repository are:\n",
    "* Custom Policy\n",
    "\n",
    "\n",
    "The intersection between this Repository and the [Gearbox](https://github.com/HoChiak/Gearbox/) Repository is shown in the following picture.\n",
    "\n",
    "<img src=\"https://https://github.com/HoChiak/Gearbox-Environment/blob/master/GearboxEnvironment.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Setting up\n",
    "\n",
    "Install the following packages and their dependencies:\n",
    "\n",
    "`pip install tensorflow==1.14.0`\n",
    "\n",
    "`pip install gym`\n",
    "\n",
    "`pip install numpy >= 1.17`\n",
    "\n",
    "`pip install keras-rl`\n",
    "\n",
    "(The exact Anaconda Environment is defined in AnacondaRepoExplicit.txt)\n",
    "\n",
    "\n",
    "Install `stable-baselines` with respect to [Guideline](https://stable-baselines.readthedocs.io/en/master/guide/install.html#prerequisites)\n",
    "\n",
    "\n",
    "Building an GYM Environment based on the original toolbox follows the explanations given in [Stable Baselines](https://stable-baselines.readthedocs.io/en/master/index.html) and [[1]](https://www.analyticsvidhya.com/blog/2017/01/introduction-to-reinforcement-learning-implementation/), [[2]](https://gym.openai.com/), [[3]](https://www.novatec-gmbh.de/en/blog/creating-a-gym-environment/), [[4]](https://ai-mrkogao.github.io/reinforcement%20learning/openaigymtutorial/), [[5]](https://medium.com/@apoddar573/making-your-own-custom-environment-in-gym-c3b65ff8cdaa) [[6]](https://towardsdatascience.com/creating-a-custom-openai-gym-environment-for-stock-trading-be532be3910e)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versions\n",
    "\n",
    "The following versions have been available:\n",
    "\n",
    "**Gearbox-Environment | Branch: 0.1 | [Gearbox Branch:](https://github.com/HoChiak/Gearbox/tree/0.6.1) 0.6.1** <u>Current Version</u>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Import Gearbox and define necessary attributes\n",
    "---\n",
    "\n",
    "Import [Gearbox](https://github.com/HoChiak/Gearbox/) and associates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gearbox import Gearbox\n",
    "import gearbox_functions as gf\n",
    "from GearboxParams import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_rlalgor = 'PPO2' # 'PPO2', 'DQN'\n",
    "flag_stblbsln = 'common' # 'common' for PPO, | 'deepq' for DQN\n",
    "total_timesteps = int(2e5)\n",
    "nolc_step = 5e5\n",
    "gamma = 0#.99\n",
    "learning_rate = 0.00025\n",
    "tensorboard_log = './%s/' % (tag+'_'+flag_rlalgor)\n",
    "no_conv_layer = 1\n",
    "stride = 10\n",
    "n_filters = 1\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Gearbox Input Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotational_frequency_in = 1300/60*41/21 # U/s | float\n",
    "number_of_load_cycle = 0 # | Must be float in .3f \n",
    "sample_interval = 0.25 # s | float\n",
    "sample_rate =int(51200/2)#/4 # Hz | float 4\n",
    "seed = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get Initial Torque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_time = gf.get_sample_time_torque(rotational_frequency_in, sample_rate, GearIn['no_teeth'], GearOut['no_teeth'])\n",
    "initial_torque = np.ones(sample_time.shape) * 200 # Nm | array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Initialize a new Instance of Gearbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gearbox = Gearbox(rotational_frequency_in,\n",
    "                  sample_interval, sample_rate,\n",
    "                  # Vibration Arguments\n",
    "                  GearIn, GearOut,\n",
    "                  Bearing1, Bearing2, Bearing3, Bearing4,\n",
    "                  # Degradation Arguments\n",
    "                  Deg_GearIn, Deg_GearOut,\n",
    "                  Deg_Bearing1, Deg_Bearing2, Deg_Bearing3, Deg_Bearing4,\n",
    "                  # Shared Arguments\n",
    "                  seed=seed,\n",
    "                  verbose=1, # 0: no output of \"load cycle #### done\"\n",
    "                  fixed_start=True,\n",
    "                  GearDegVibDictIn=GearDegVibDictIn,\n",
    "                  GearDegVibDictOut=GearDegVibDictOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "# Define Interpreter, Vibration2State and Action2Torque\n",
    "---\n",
    "\n",
    "Besides the agent there are three other modules (Interpreter, Vibration2State, Action2Torque) which will be defined in the following.\n",
    "\n",
    "<img src=\"https://https://github.com/HoChiak/Gearbox-Environment/blob/master/GearboxEnvironment.png\" width=\"60%\">\n",
    "\n",
    "Load Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Build In\n",
    "import os\n",
    "from copy import deepcopy as dc\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Third Party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Gym and Stable Baselines\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "# from gym.utils import seeding\n",
    "from stable_baselines.common.env_checker import check_env\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter_choice = 'step1' \n",
    "\n",
    "\n",
    "def interpreter(vibrations, nolc, interpreter_parameters):\n",
    "    \"\"\"\n",
    "    Interpreter for Gearbox Environment.\n",
    "    Type of interpreter function(s) can be choosen by:\n",
    "    interpreter_parameters['interpreter_choice']\n",
    "    More than one option can be specified (summed up)\n",
    "    Options implemented:\n",
    "    ----\n",
    "    step1:  Gives constant reward by given number of \n",
    "            load cycle (nolc)\n",
    "    ----\n",
    "    Argument 'interpreter_parameters' is input \n",
    "    and output -> used for recursive calculations etc.\n",
    "    ---\n",
    "    \n",
    "    \"\"\"\n",
    "    # Placeholder\n",
    "    rewards = []\n",
    "    if 'step1' in interpreter_parameters['interpreter_choice']:\n",
    "        # ------ Get same normed reward each step\n",
    "        reward1 = (nolc-interpreter_parameters['prev_values']['nolc']) / 1e6\n",
    "        reward1 = float(reward1)\n",
    "        # Append\n",
    "        rewards.append(reward1)\n",
    "        # To keep return unchanged argument metric must be defined\n",
    "        metric = None\n",
    "    reward = float(sum(rewards)) # ensure reward is scalar float\n",
    "    return(reward, {'prev_values': {'nolc': nolc}, 'interpreter_choice': interpreter_parameters['interpreter_choice']})\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Parameters for kwargs\n",
    "interpreter_parameters = {'prev_values': {'nolc': 0\n",
    "                                         },\n",
    "                          'interpreter_choice': interpreter_choice}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vibrations2Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vibrations2observations(vibrations, observation_parameters):\n",
    "    \"\"\"\n",
    "    Shaping Vibrations into Observations for Gearbox Environment.\n",
    "    Calculation is done as follows\n",
    "    ----\n",
    "    1. Standardize features by removing the mean and scaling to \n",
    "    unit variance - using recursive mean and variance calculations\n",
    "    (limiting change from step to step for more stable results)\n",
    "    2. Limit observations to: -5 < obs < 5\n",
    "    ----\n",
    "    Argument 'observation_parameters' is input \n",
    "    and output -> used for recursive calculations etc.\n",
    "    ---\n",
    "    \"\"\"\n",
    "    # Get current recursive mean and variance\n",
    "    if observation_parameters['prev_values']['mean'] is np.nan:\n",
    "        mean = np.mean(vibrations)\n",
    "        var = np.var(vibrations)\n",
    "    else:\n",
    "        # Recursive Averaging by given weight\n",
    "        weight_new = 2\n",
    "        mean = (( observation_parameters['prev_values']['mean'] * observation_parameters['prev_values']['n'] + np.mean(vibrations) * weight_new) / (observation_parameters['prev_values']['n'] + 1 * weight_new))\n",
    "        var = (( observation_parameters['prev_values']['var'] * observation_parameters['prev_values']['n'] + np.var(vibrations) * weight_new) / (observation_parameters['prev_values']['n'] + 1 * weight_new))\n",
    "    obs = (vibrations - mean) / np.power(var, 0.5)\n",
    "    n = observation_parameters['prev_values']['n'] + 1\n",
    "    obs = obs.reshape(-1, 1)\n",
    "    obs[obs < -5] = -5\n",
    "    obs[obs > 5] = 5           \n",
    "    return(obs, {'prev_values': {'mean': mean, 'var': var, 'n': n}})\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Parameters for kwargs\n",
    "observation_parameters = {'prev_values': {'mean': np.nan, 'var': np.nan, 'n': 0}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Observation Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation_space = spaces.Box(low=-5, high=5,\n",
    "                        shape=(np.floor(sample_interval*sample_rate).astype(np.int32), 1),\n",
    "                        dtype= np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action2Torque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions take the Agents output (integer determining the tooth to reduce torque at) and output a torque signal with respect to the reducement. Further explaination will be updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_actions = GearIn['no_teeth'] + 1\n",
    "rotational_frequency_in = 1300/60*41/21\n",
    "sample_rate = 51200/4\n",
    "\n",
    "def get_binary_load_dict(no_teeth, reduce_at_tooth=None, reduce_to_torque=None, standard_torque=200):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    balance_torque = standard_torque + (standard_torque - reduce_to_torque) / (no_teeth - 1)\n",
    "    load_dict = {'%i' % (idx): balance_torque for idx in range(1, no_teeth+1) if idx!=reduce_at_tooth}\n",
    "    load_dict['%i' % (reduce_at_tooth)] = reduce_to_torque\n",
    "    return(load_dict)\n",
    "\n",
    "\n",
    "def repeat2no_values(vector, no_values):\n",
    "    \"\"\"\n",
    "    Repeat the given vector as many times needed,\n",
    "    to create a repeat_vector of given number of\n",
    "    values (no_values)\n",
    "    \"\"\"\n",
    "    # Calculate number of repetitions\n",
    "    no_values_vector = vector.shape[0]\n",
    "    repetitions = np.ceil((no_values / no_values_vector))\n",
    "    repetitions = int(repetitions) #dtype decl. not working\n",
    "    # Repeat Vetor\n",
    "    repeat_vector = np.tile(vector, repetitions)\n",
    "    # Trim to final length\n",
    "    repeat_vector = np.delete(repeat_vector,\n",
    "                              np.s_[no_values:], axis=0)\n",
    "    return(repeat_vector)\n",
    "\n",
    "\n",
    "def get_cids(time, time_shift, time_start=0, id_start=0):\n",
    "    \"\"\"\n",
    "    Shift a given signal by a given time shift.\n",
    "    \"\"\"\n",
    "    # Shift signal for each gear\n",
    "    ti, tv = id_start, time_start\n",
    "    #shifted_signal = np.zeros((time.shape[0], 1))\n",
    "    cid_list = list()\n",
    "    while tv < (max(time)+time_shift):\n",
    "        # Add current center id to list\n",
    "        cid_list.append(ti)\n",
    "        # Get new shift arguments\n",
    "        tv += time_shift\n",
    "        ti = np.argmin(np.abs(time - tv))\n",
    "    # Remove first zero axis\n",
    "    #shifted_signal = np.delete(shifted_signal, 0, 1)\n",
    "    return(cid_list)\n",
    "\n",
    "\n",
    "def torque_from_dict(load_dict, rotational_frequency, sample_time, get_cids=get_cids):\n",
    "    \"\"\"\n",
    "    Method to determine an aquivalent load for each tooth.\n",
    "    Returns a dictionary containing a list of mean loads\n",
    "    per tooth. E.g.\n",
    "    '1': [155, 177, 169,....]\n",
    "    '2': [196, 155, 169,....]\n",
    "    '3' ...\n",
    "    ....\n",
    "    \"\"\"\n",
    "    no_teeth = len(load_dict)\n",
    "    time2tooth = (1 / rotational_frequency) / no_teeth\n",
    "    teeth_cid_list = get_cids(time=sample_time, time_shift=time2tooth,\n",
    "                                  time_start=0, id_start=0)\n",
    "    teeth_numbering = np.arange(1, no_teeth+0.1, 1, dtype=np.int32)\n",
    "    teeth_no_list = repeat2no_values(teeth_numbering, no_values=len(teeth_cid_list))\n",
    "    # Get Tooth Center IDs\n",
    "    ids_array = np.array(teeth_cid_list)\n",
    "    ids_array = ids_array.reshape(-1, 1)\n",
    "    # Get distance between 2 tooth in no ids\n",
    "    dist_ids = ids_array[1] - ids_array[0]\n",
    "    # Take half\n",
    "    dist_ids = dist_ids / 2\n",
    "    # Get upper and lower bound\n",
    "    #ids_low = np.floor(ids_array - dist_ids)\n",
    "    ids_up = np.floor(ids_array + dist_ids)\n",
    "    # Correct for highest and lowest possible id\n",
    "    #ids_low[ids_low < 0] = 0\n",
    "    ids_up[ids_up > (sample_time.size -1)] = sample_time.size\n",
    "    ids_up = ids_up.tolist()\n",
    "    # Add to one array\n",
    "    #ids_bounds = np.concatenate([ids_low, ids_up], axis=1).astype(dtype=np.int32)\n",
    "    # Get empty array\n",
    "    torque = np.zeros(sample_time.shape)\n",
    "    # Iterate over torque and get mean value of load per tooth and load cycle\n",
    "    id_low = int(0)\n",
    "    for idx, id_up in enumerate(ids_up):\n",
    "        torque[id_low:int(id_up[0])] = load_dict[str(teeth_no_list[idx])]\n",
    "        id_low = int(id_up[0])\n",
    "    return(torque)\n",
    "\n",
    "# ------------------------------------------------\n",
    "# Change the following paragraph for different learning approaches\n",
    "# ------------------------------------------------\n",
    "def action2torque(action, initial_torque,\n",
    "                  action_parameters):\n",
    "    \"\"\"\n",
    "    Takes an Action (integer) and outputs an torque\n",
    "    signal\n",
    "    Every other used function must be passed by \n",
    "    action parameters!\n",
    "    \"\"\"\n",
    "    reduce_at_tooth = int(action)\n",
    "    if reduce_at_tooth == 0:\n",
    "        \"\"\"\n",
    "        Do nothing and return initial torque\n",
    "        \"\"\"\n",
    "        return(initial_torque)\n",
    "    else:\n",
    "        \"\"\"\n",
    "        Reduce at tooth given by action integer\n",
    "        \"\"\"\n",
    "        get_binary_load_dict = action_parameters['get_binary_load_dict']\n",
    "        load_dict = get_binary_load_dict(action_parameters['no_actions'] - 1,\n",
    "                                         reduce_at_tooth=reduce_at_tooth,\n",
    "                                         reduce_to_torque=190,\n",
    "                                         standard_torque=200)\n",
    "        get_sample_time_torque = action_parameters['get_sample_time_torque']\n",
    "        sample_time = get_sample_time_torque(action_parameters['rotational_frequency'],\n",
    "                                            action_parameters['sample_rate'],\n",
    "                                            action_parameters['GearIn_teeth'],\n",
    "                                            action_parameters['GearOut_teeth'])\n",
    "        torque_from_dict = action_parameters['torque_from_dict']\n",
    "        get_cids = action_parameters['get_cids']\n",
    "        torque = torque_from_dict(load_dict, action_parameters['rotational_frequency'],\n",
    "                                    sample_time, get_cids=get_cids)\n",
    "        return(np.array(torque).astype(np.float64))\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "# Parameters for kwargs\n",
    "action_parameters = {'no_actions': no_actions,\n",
    "                     'rotational_frequency': rotational_frequency_in,\n",
    "                     'sample_rate': sample_rate,\n",
    "                     'GearIn_teeth': GearIn['no_teeth'],\n",
    "                     'GearOut_teeth': GearOut['no_teeth'],\n",
    "                     'get_binary_load_dict': get_binary_load_dict,\n",
    "                     'get_sample_time_torque': gf.get_sample_time_torque,\n",
    "                     'torque_from_dict': torque_from_dict,\n",
    "                     'get_cids': get_cids\n",
    "                    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Action Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = spaces.Discrete(no_actions) # Add one, if action=0 do nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Gearbox-Environment OpenAI-Style (Gym)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PseudoCode \n",
    "\n",
    "\n",
    "**Define a class 'GearboxBaseEnv' and initialize by giving gearbox, interpreter, action2torque, vibrations2observations, etc.**\n",
    "\n",
    "\n",
    "```\n",
    "class GearboxBaseEnv(gym.Env):\n",
    "\n",
    "    def __init__(self, gearbox, initial_torque, *args, **kwargs):\n",
    "        \"\"\" Initialize the environment with specific settings. Settings include: \"\"\"\n",
    "        # ------------------------------------------------\n",
    "        self.gearbox = gearbox\n",
    "        ...\n",
    "        self.action_space = action_space\n",
    "        self.observation_space = observation_space\n",
    "        # ------------------------------------------------\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Define step() method taking 'action' as input and returning 'observations, reward, done and info'**\n",
    "\n",
    "```\n",
    "    def step(self, action):\n",
    "        \"\"\" Performing a step includig: Take Action, Get Reward, Get Observations and define end of episode \"\"\"\n",
    "        # ------------------------------------------------\n",
    "        ...\n",
    "        self.gearbox.set(self.nolc, self.torque)\n",
    "        self.vibrations = self.gearbox.run(self.nolc, output=True)\n",
    "        self.obs = self.vibrations2observations(self.vibrations, self.kwargs['observation_parameters'])\n",
    "        ...\n",
    "        self.reward, self.kwargs['interpreter_parameters'] = self.interpreter([self.vibrations], self.nolc, self.kwargs['interpreter_parameters'])\n",
    "        # ------------------------------------------------\n",
    "        return(self.obs, self.reward, self.done, self.info)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Define reset() method resetting environment after episode**\n",
    "```\n",
    "    def reset(self):\n",
    "        \"\"\" Reinitialize Environment and reset initial settings \"\"\"\n",
    "        # ------------------------------------------------\n",
    "        self.action = 0 # apply initial_torque\n",
    "        self.vibrations = self.gearbox.run(self.nolc, output=True)\n",
    "        self.obs = self.vibrations2observations(self.vibrations, self.kwargs['observation_parameters'])\n",
    "        ...\n",
    "        # ------------------------------------------------\n",
    "        return(self.obs)\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Define render() method to ouput some information**\n",
    "\n",
    "```\n",
    "    def render(self, mode='ansi', close=False):\n",
    "        \"\"\" Renders the environment. \"\"\"\n",
    "        # ------------------------------------------------\n",
    "        print(txt_ansi, end=\"\\r\")\n",
    "        ...\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Define close() method to close**\n",
    "\n",
    "```\n",
    "    def close(self):\n",
    "        pass\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**Define other methods necessary for gearbox**\n",
    "\n",
    "\n",
    "```\n",
    "    def nextseed(self):\n",
    "        \"\"\"\n",
    "        Method to get new seed for next episode,\n",
    "        different than previous seed.\n",
    "        \"\"\"\n",
    "        seed = dc(self.seed)\n",
    "        seed += np.random.randint(1, high=10, size=1, dtype=np.int32)[0]\n",
    "        if seed > 2**16:\n",
    "            seed = seed - 2**16\n",
    "        return(seed)\n",
    "\n",
    "\n",
    "    def check_stop_criteria(self, statei, criteria):\n",
    "        \"\"\"\n",
    "        Method to check if criteria is reached in statei.\n",
    "        Currently it checks if any gear pitting is >= criteria,\n",
    "        e.g. 4 %.\n",
    "        Returns False if stop criteria is not reached\n",
    "        Returns True if stop criteria is reached\n",
    "        \"\"\"\n",
    "        for key in statei.keys():\n",
    "            if statei[key] is not None:\n",
    "                if (statei[key] >= criteria).to_numpy().any():\n",
    "                    return(False)\n",
    "        return(True)\n",
    "\n",
    "    def startpoint_detection(self):\n",
    "        if self.gearbox.Degradation.GearIn_Degradation.state0 is not None:\n",
    "            gearin_n0_min = min(self.gearbox.Degradation.GearIn_Degradation.state0['n0'])\n",
    "        else:\n",
    "            gearin_n0_min = np.inf\n",
    "        if self.gearbox.Degradation.GearOut_Degradation.state0 is not None:\n",
    "            gearout_n0_min = min(self.gearbox.Degradation.GearOut_Degradation.state0['n0'])\n",
    "        else:\n",
    "            gearout_n0_min = np.inf\n",
    "\n",
    "        n0_min = min(gearin_n0_min, gearout_n0_min)\n",
    "        n0_min = max(n0_min, 0)\n",
    "        remainder = n0_min % self.nolc_step\n",
    "        startpoint = n0_min - remainder + self.nolc_step\n",
    "        return(startpoint)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Code (Non-PseudoCode) formulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GearboxBaseEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['ansi']} # should contain all available render modes\n",
    "\n",
    "    def __init__(self, gearbox, initial_torque,\n",
    "                 nolc_step,\n",
    "                 interpreter=None,\n",
    "                 vibrations2observations=None,\n",
    "                 action2torque=None,\n",
    "                 observation_space=None,\n",
    "                 action_space=None,\n",
    "                 stop_criteria=4.0, seed=None,\n",
    "                 render_in_step=False,\n",
    "                 warn_limit=None,\n",
    "                 verbose=0,\n",
    "                 render_mode='ansi2',\n",
    "                 dense=True, # if False reward will only given when self.done = True\n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize the environment with specific settings. Settings include:\n",
    "        env: gearbox environment\n",
    "        done: is True if end of episode is reached\n",
    "        counter: counting steps\n",
    "        action and observation space\n",
    "        \"\"\"\n",
    "        assert interpreter is not None, 'Function interpreter() must be given'\n",
    "        assert vibrations2observations is not None, 'Function vibrations2observations() must be given'\n",
    "        assert action2torque is not None, 'Function action2torque() must be given'\n",
    "        assert action_space is not None, 'Gym Spaces action_space must be given'\n",
    "        assert observation_space is not None, 'Gym Spaces observation_space must be given'\n",
    "        # ------------------------------------------------\n",
    "        # Init Dummy Environment --> first real initialization is done in reset()\n",
    "        # ------------------------------------------------\n",
    "        self.gearbox = gearbox\n",
    "        self.initial_torque = np.array(initial_torque).astype(np.float64)\n",
    "        # Initialize here and only reinitialize in reset()\n",
    "        self.gearbox.initialize(self.initial_torque)\n",
    "        self.nolc_step = nolc_step\n",
    "        self.interpreter = interpreter\n",
    "        self.vibrations2observations = vibrations2observations\n",
    "        self.action2torque = action2torque\n",
    "        self.stop_criteria = stop_criteria\n",
    "        self.seed = seed\n",
    "        self.render_in_step = render_in_step\n",
    "        self.warn_limit = warn_limit\n",
    "        self.verbose = verbose\n",
    "        self.render_mode = render_mode\n",
    "        self.dense = dense\n",
    "        self.kwargs = kwargs\n",
    "        self.kwargs_init = dc(kwargs)\n",
    "        # Until done is False -> keeprunning\n",
    "        self.done = False\n",
    "        self.counter = 0\n",
    "        self.episode = -1\n",
    "        self.reward = np.nan\n",
    "        self.infos = []\n",
    "        self.render_len_max = 0\n",
    "        np.random.seed(seed)\n",
    "        tf.compat.v1.set_random_seed(seed)\n",
    "        # ------------------------------------------------\n",
    "        # Change the following paragraph for different learning approaches\n",
    "        # ------------------------------------------------\n",
    "        self.action_space = action_space\n",
    "        self.observation_space = observation_space\n",
    "        # ------------------------------------------------\n",
    "\n",
    "## STEP defined in a Way to prevend recursive reward!!!\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Performing a step includig: Take Action, Get Reward,\n",
    "        Get Observations and define end of episode\n",
    "\n",
    "        \"\"\"\n",
    "        assert self.action_space.contains(action), \"%r (%s) invalid\" % (action, type(action))\n",
    "        self.action = action\n",
    "        # ------------------------------------------------\n",
    "        # Take Action at previous nolc\n",
    "        # ------------------------------------------------\n",
    "        self.torque = self.action2torque(action, self.initial_torque,\n",
    "                                         self.kwargs['action_parameters'])\n",
    "        self.gearbox.set(self.nolc, self.torque)\n",
    "        # ------------------------------------------------\n",
    "        # Go to current nolc\n",
    "        # ------------------------------------------------\n",
    "        self.nolc += self.nolc_step\n",
    "        self.counter += 1\n",
    "        # ------------------------------------------------\n",
    "        # Get Observations\n",
    "        # ------------------------------------------------\n",
    "        self.vibrations = self.gearbox.run(self.nolc, output=True)\n",
    "        self.obs, self.kwargs['observation_parameters'] = self.vibrations2observations(self.vibrations, self.kwargs['observation_parameters'])\n",
    "        # ------------------------------------------------\n",
    "        # Check Done\n",
    "        # ------------------------------------------------\n",
    "        self.done = not(self.check_stop_criteria(self.gearbox.ga_statei[-1], self.stop_criteria))\n",
    "        # ------------------------------------------------\n",
    "        # Warn if nolc limit is given\n",
    "        # ------------------------------------------------\n",
    "        if self.warn_limit is not None:\n",
    "            if self.nolc >= self.warn_limit:\n",
    "                warnings.warn('The current load cycle exceeded the warning limit, episode will be ended.', UserWarning)\n",
    "                self.done = True\n",
    "                self.gearbox.Degradation.summary_degradation()\n",
    "        # ------------------------------------------------\n",
    "        # Get Rewards\n",
    "        # Change the following paragraph for different learning approaches\n",
    "        # ------------------------------------------------\n",
    "        if (not(self.dense) and not(self.done)):\n",
    "            self.reward = 0\n",
    "        else:\n",
    "            self.reward, self.kwargs['interpreter_parameters'] = self.interpreter([self.vibrations], self.nolc, self.kwargs['interpreter_parameters'])\n",
    "        # ------------------------------------------------\n",
    "        # Get Info\n",
    "        # ------------------------------------------------\n",
    "        if (self.verbose==1 or (self.verbose==2 and self.done)):\n",
    "            self.info['counter'] = self.counter\n",
    "            self.info['episode'] = self.episode\n",
    "            self.info['nolc'] = self.nolc\n",
    "            # self.info['observations'] = self.obs\n",
    "            self.info['action'] = action\n",
    "            self.info['reward'] = self.reward\n",
    "            try:\n",
    "                self.info['prev_values'] = self.kwargs['interpreter_parameters']['prev_values']\n",
    "            except:\n",
    "                pass\n",
    "            # self.info['history'] = [-1]\n",
    "            self.infos.append(dc(self.info))\n",
    "        # ------------------------------------------------\n",
    "        # Render if render_in_step is True\n",
    "        # ------------------------------------------------\n",
    "        if self.render_in_step:\n",
    "            self.render()\n",
    "        # ------------------------------------------------\n",
    "        # Return Observations, Reward, Done, Info\n",
    "        # ------------------------------------------------\n",
    "        return(self.obs, self.reward, self.done, self.info)\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        REinitialize Environment and reset initial settings\n",
    "        \"\"\"\n",
    "        # ------------------------------------------------\n",
    "        # Change the following paragraph for different learning approaches\n",
    "        # ------------------------------------------------\n",
    "        self.action = 0 # apply initial_torque\n",
    "        # ------------------------------------------------\n",
    "        # Init Environment\n",
    "        # ------------------------------------------------\n",
    "        self.gearbox.ga_seed = self.seed\n",
    "        # REinitialize() only resets Degradation (~50times faster than initialize())\n",
    "        self.gearbox.reinitialize(self.initial_torque)\n",
    "        # Until done is False -> keeprunning\n",
    "        self.done = not(self.check_stop_criteria(self.gearbox.ga_statei[-1], self.stop_criteria))\n",
    "        self.counter = 0\n",
    "        self.episode += 1\n",
    "        # Get new seeding\n",
    "        self.seed = self.nextseed()\n",
    "        self.kwargs = dc(self.kwargs_init)\n",
    "        # ------------------------------------------------\n",
    "        # Change the following paragraph for different learning approaches\n",
    "        # ------------------------------------------------\n",
    "        self.nolc = self.startpoint_detection()\n",
    "        self.vibrations = self.gearbox.run(self.nolc, output=True)\n",
    "        self.obs, self.kwargs['observation_parameters'] = self.vibrations2observations(self.vibrations, self.kwargs['observation_parameters'])\n",
    "        # ------------------------------------------------\n",
    "        # Get Info\n",
    "        # ------------------------------------------------\n",
    "        self.info = {}\n",
    "        if (self.verbose==1 or (self.verbose==2 and self.done)):\n",
    "            self.info['counter'] = self.counter\n",
    "            self.info['episode'] = self.episode\n",
    "            self.info['nolc'] = self.nolc\n",
    "            # self.info['observations'] = self.obs\n",
    "            self.info['action'] = None\n",
    "            self.info['reward'] = None\n",
    "            try:\n",
    "                self.info['prev_values'] = self.kwargs['interpreter_parameters']['prev_values']\n",
    "            except:\n",
    "                pass\n",
    "            # self.info['history'] = [-1]\n",
    "            self.infos.append(dc(self.info))\n",
    "        # ------------------------------------------------\n",
    "        # Return Observations\n",
    "        # ------------------------------------------------\n",
    "        return(self.obs)\n",
    "\n",
    "    def render(self, mode='ansi', close=False):\n",
    "        \"\"\"Renders the environment.\n",
    "        The set of supported modes varies per environment. (And some\n",
    "        environments do not support rendering at all.) By convention,\n",
    "        if mode is:\n",
    "        - human: render to the current display or terminal and\n",
    "          return nothing. Usually for human consumption.\n",
    "        - rgb_array: Return an numpy.ndarray with shape (x, y, 3),\n",
    "          representing RGB values for an x-by-y pixel image, suitable\n",
    "          for turning into a video.\n",
    "        - ansi: Return a string (str) or StringIO.StringIO containing a\n",
    "          terminal-style text representation. The text can include newlines\n",
    "          and ANSI escape sequences (e.g. for colors).\n",
    "        Note:\n",
    "            Make sure that your class's metadata 'render.modes' key includes\n",
    "              the list of supported modes. It's recommended to call super()\n",
    "              in implementations to use the functionality of this method.\n",
    "        Args:\n",
    "            mode (str): the mode to render with\n",
    "        Example:\n",
    "        class MyEnv(Env):\n",
    "            metadata = {'render.modes': ['human', 'rgb_array']}\n",
    "            def render(self, mode='human'):\n",
    "                if mode == 'rgb_array':\n",
    "                    return np.array(...) # return RGB frame suitable for video\n",
    "                elif mode == 'human':\n",
    "                    ... # pop up a window and render\n",
    "                else:\n",
    "                    super(MyEnv, self).render(mode=mode) # just raise an exception\n",
    "        \"\"\"\n",
    "        mode=self.render_mode\n",
    "\n",
    "        if mode == 'rgb_array': # return RGB frame suitable for video\n",
    "            pass\n",
    "        elif mode == 'human': # pop up a window and render\n",
    "            pass\n",
    "        elif mode == 'ansi1': # return terminal-style text representation\n",
    "            # ------------------------------------------------\n",
    "            # Get Text Fragments\n",
    "            # ------------------------------------------------\n",
    "            txt_teeth = list(self.gearbox.Degradation.GearIn_Degradation.state0['tooth'].to_numpy().reshape(-1))\n",
    "            # # Boxes  of fallen teeth (same style as taken action) - currently unused\n",
    "            #txt_truth = ' '.join(['%i:' % (i) + u'\\u25FB' if i not in dam_teeth else '%i:' % (i) + u'\\u25FC' for i in range(int(action_space.n))])\n",
    "            txt_pred = ' '.join(['%i:' % (i) + u'\\u25FB' if i != self.action else '%i:' % (i) + u'\\u25FC' for i in range(int(self.action_space.n))])\n",
    "            lc = '@ %i' % (int(self.gearbox.ga_load_cycle[-1]))\n",
    "            # ------------------------------------------------\n",
    "            # Text = fallen teeth + Taken Action + Load cycle\n",
    "            # ------------------------------------------------\n",
    "            txt_ansi = 'T: %s | P: %s | %s'% (str(txt_teeth), txt_pred, lc)\n",
    "            # ------------------------------------------------\n",
    "            # Add whitespace if a longer text before was printed\n",
    "            # ------------------------------------------------\n",
    "            self.render_len_max = max([len(txt_ansi), self.render_len_max])\n",
    "            len_diff = max([len(txt_ansi) - self.render_len_max, 0])\n",
    "            txt_ansi += ' ' * len_diff\n",
    "            print(txt_ansi, end=\"\\r\")\n",
    "        elif mode == 'ansi2': # return terminal-style text representation for running in batch\n",
    "            # ------------------------------------------------\n",
    "            # Get Text Fragments\n",
    "            # ------------------------------------------------\n",
    "            txt_teeth = list(self.gearbox.Degradation.GearIn_Degradation.state0['tooth'].to_numpy().reshape(-1))\n",
    "            # # Boxes  of fallen teeth (same style as taken action) - currently unused\n",
    "            #txt_truth = ' '.join(['%i:' % (i) + u'\\u25FB' if i not in dam_teeth else '%i:' % (i) + u'\\u25FC' for i in range(int(self.action_space.n))])\n",
    "            lc = '@ %i' % (int(self.gearbox.ga_load_cycle[-1]))\n",
    "            # ------------------------------------------------\n",
    "            # Text = fallen teeth + Taken Action + Load cycle\n",
    "            # ------------------------------------------------\n",
    "            txt_ansi = 'Truth: %s | Aktion: %s | Reward: %.3f | %s'% (str(txt_teeth), str(self.action), self.reward, lc)\n",
    "            # ------------------------------------------------\n",
    "            # Add whitespace if a longer text before was printed\n",
    "            # ------------------------------------------------\n",
    "            self.render_len_max = max([len(txt_ansi), self.render_len_max])\n",
    "            len_diff = max([len(txt_ansi) - self.render_len_max, 0])\n",
    "            txt_ansi += ' ' * len_diff\n",
    "            print(txt_ansi, end=\"\\r\")\n",
    "        else:\n",
    "            pass\n",
    "        # ------------------------------------------------\n",
    "        # If Done true print new line to start new line for next\n",
    "        # ------------------------------------------------\n",
    "        if self.done:\n",
    "            print('\\n')\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "# ------------------------------------------------\n",
    "    def nextseed(self):\n",
    "        \"\"\"\n",
    "        Method to get new seed for next episode,\n",
    "        different than previous seed.\n",
    "        \"\"\"\n",
    "        seed = dc(self.seed)\n",
    "        seed += np.random.randint(1, high=10, size=1, dtype=np.int32)[0]\n",
    "        if seed > 2**16:\n",
    "            seed = seed - 2**16\n",
    "        return(seed)\n",
    "\n",
    "\n",
    "    def check_stop_criteria(self, statei, criteria):\n",
    "        \"\"\"\n",
    "        Method to check if criteria is reached in statei.\n",
    "        Currently it checks if any gear pitting is >= criteria,\n",
    "        e.g. 4 %.\n",
    "        Returns False if stop criteria is not reached\n",
    "        Returns True if stop criteria is reached\n",
    "        \"\"\"\n",
    "        for key in statei.keys():\n",
    "            if statei[key] is not None:\n",
    "                if (statei[key] >= criteria).to_numpy().any():\n",
    "                    return(False)\n",
    "        return(True)\n",
    "\n",
    "    def startpoint_detection(self):\n",
    "        if self.gearbox.Degradation.GearIn_Degradation.state0 is not None:\n",
    "            gearin_n0_min = min(self.gearbox.Degradation.GearIn_Degradation.state0['n0'])\n",
    "        else:\n",
    "            gearin_n0_min = np.inf\n",
    "        if self.gearbox.Degradation.GearOut_Degradation.state0 is not None:\n",
    "            gearout_n0_min = min(self.gearbox.Degradation.GearOut_Degradation.state0['n0'])\n",
    "        else:\n",
    "            gearout_n0_min = np.inf\n",
    "\n",
    "        n0_min = min(gearin_n0_min, gearout_n0_min)\n",
    "        n0_min = max(n0_min, 0)\n",
    "        remainder = n0_min % self.nolc_step\n",
    "        startpoint = n0_min - remainder + self.nolc_step\n",
    "        return(startpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Custom Policy\n",
    "---\n",
    "\n",
    "This policy is build to use 'Conv1D' Layers\n",
    "\n",
    "Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.a2c.utils import conv, linear, conv_to_fc\n",
    "from stable_baselines.common.tf_layers import ortho_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The modified Conv1D Layer based on [stable baselines conv definition](https://github.com/openai/baselines/blob/ea25b9e8b234e6ee1bca43083f8f3cf974143998/baselines/a2c/utils.py#L37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d(input_tensor, scope, *, n_filters, filter_size, stride,\n",
    "         pad='VALID', init_scale=1.0, data_format='NHWC', one_dim_bias=False):\n",
    "    \"\"\"\n",
    "    Creates a 2d convolutional layer for TensorFlow\n",
    "    :param input_tensor: (TensorFlow Tensor) The input tensor for the convolution\n",
    "    :param scope: (str) The TensorFlow variable scope\n",
    "    :param n_filters: (int) The number of filters\n",
    "    :param filter_size:  (Union[int, [int], tuple<int, int>]) The filter size for the squared kernel matrix,\n",
    "    or the height and width of kernel filter if the input is a list or tuple\n",
    "    :param stride: (int) The stride of the convolution\n",
    "    :param pad: (str) The padding type ('VALID' or 'SAME')\n",
    "    :param init_scale: (int) The initialization scale\n",
    "    :param data_format: (str) The data format for the convolution weights\n",
    "    :param one_dim_bias: (bool) If the bias should be one dimentional or not\n",
    "    :return: (TensorFlow Tensor) 2d convolutional layer\n",
    "    \"\"\"\n",
    "    # if isinstance(filter_size, list) or isinstance(filter_size, tuple):\n",
    "    #     assert len(filter_size) == 2, \\\n",
    "    #         \"Filter size must have 2 elements (height, width), {} were given\".format(len(filter_size))\n",
    "    #     filter_height = filter_size[0]\n",
    "    #     filter_width = filter_size[1]\n",
    "    # else:\n",
    "    #     filter_height = filter_size\n",
    "    #     filter_width = filter_size\n",
    "    if data_format == 'NHWC':\n",
    "        channel_ax = 2\n",
    "        strides = [1, stride, 1]\n",
    "        bshape = [1, 1, n_filters]\n",
    "    elif data_format == 'NCHW':\n",
    "        channel_ax = 1\n",
    "        strides = [1, 1, stride]\n",
    "        bshape = [1, n_filters, 1]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    bias_var_shape = [n_filters] if one_dim_bias else [1, n_filters, 1]\n",
    "    n_input = input_tensor.get_shape()[channel_ax].value\n",
    "    wshape = [filter_size, n_input, n_filters]\n",
    "    with tf.variable_scope(scope):\n",
    "        # tbd set initilialiser to sensor shaped [0.5, 1, 0.5, 0, 0, 0, 0,] and trainable false\n",
    "        weight = tf.get_variable(\"w\", wshape, initializer=None)\n",
    "        bias = tf.get_variable(\"b\", bias_var_shape, initializer=tf.constant_initializer(0.0))\n",
    "        if not one_dim_bias and data_format == 'NHWC':\n",
    "            bias = tf.reshape(bias, bshape)\n",
    "        return bias + tf.nn.conv1d(input_tensor, weight, stride=strides, padding=pad, data_format=data_format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define modified cnn policy [Source](https://github.com/hill-a/stable-baselines/issues/220)\n",
    "\n",
    "Number of conv layers and for each layer filter_size, stride and number of filters must be defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_cnn(scaled_images, *args, **kwargs):\n",
    "    activ = tf.nn.relu\n",
    "    x = activ(conv1d(scaled_images, 'c1', n_filters=l1_n_filters, filter_size=l1_filter_size, stride=l1_stride, init_scale=np.sqrt(2), **kwargs))\n",
    "    if no_conv_layer >= 2:\n",
    "        x = activ(conv1d(x, 'c2', n_filters=l2_n_filters, filter_size=l2_filter_size, stride=l2_stride, init_scale=np.sqrt(2), **kwargs))\n",
    "    if no_conv_layer >= 3:\n",
    "        x = activ(conv1d(x, 'c3', n_filters=l3_n_filters, filter_size=l3_filter_size, stride=l3_stride, init_scale=np.sqrt(2), **kwargs))\n",
    "    if no_conv_layer >= 4:\n",
    "        x = activ(conv1d(x, 'c4', n_filters=l4_n_filters, filter_size=l4_filter_size, stride=l4_stride, init_scale=np.sqrt(2), **kwargs))\n",
    "    x = conv_to_fc(x)\n",
    "    return activ(linear(x, 'fc1', n_hidden=n_hidden, init_scale=np.sqrt(2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differ between deepq and common policies\n",
    "\n",
    "Using 'deepq':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.deepq.policies import FeedForwardPolicy, CnnPolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 'common':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines.common.policies import FeedForwardPolicy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ANN to custom Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPolicy(FeedForwardPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomPolicy, self).__init__(*args, **kwargs, cnn_extractor=modified_cnn, feature_extraction=\"cnn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "# Putting Everything together\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Initialize a new Instance (set verbose to zero):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gearbox = Gearbox(rotational_frequency_in,\n",
    "                  sample_interval, sample_rate,\n",
    "                  # Vibration Arguments\n",
    "                  GearIn, GearOut,\n",
    "                  Bearing1, Bearing2, Bearing3, Bearing4,\n",
    "                  # Degradation Arguments\n",
    "                  Deg_GearIn, Deg_GearOut,\n",
    "                  Deg_Bearing1, Deg_Bearing2, Deg_Bearing3, Deg_Bearing4,\n",
    "                  # Shared Arguments\n",
    "                  seed=seed,\n",
    "                  verbose=0, # 0: no output of \"load cycle #### done\"\n",
    "                  fixed_start=True,\n",
    "                  GearDegVibDictIn=GearDegVibDictIn,\n",
    "                  GearDegVibDictOut=GearDegVibDictOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = GearboxBaseEnv(gearbox, initial_torque, nolc_step=nolc_step,\n",
    "                     interpreter=interpreter,\n",
    "                     vibrations2observations=vibrations2observations,\n",
    "                     action2torque=action2torque,\n",
    "                     observation_space=observation_space,\n",
    "                     action_space=action_space,\n",
    "                     stop_criteria=4.0, seed=8,\n",
    "                     render_in_step=True, # using render method in each step\n",
    "                     warn_limit=30e6, # force env.done if limit is reached\n",
    "                     verbose=0,# 0:save no infos, 1:save infos each step, 2: save info episode end\n",
    "                     render_mode='ansi2', #ansi1 more detailes (for ipynb) and ansi2 less detailed (for terminal)\n",
    "                     # kwargs\n",
    "                     interpreter_parameters=interpreter_parameters,\n",
    "                     observation_parameters=observation_parameters, # neccesary, can be empty dict\n",
    "                     action_parameters=action_parameters) # neccesary, can be empty dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Agent\n",
    "\n",
    "E.g. using 'DQN':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import DQN\n",
    "model = DQN(CustomPolicy, env,\n",
    "            gamma=gamma, learning_rate=learning_rate,\n",
    "            verbose=1, tensorboard_log=tensorboard_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g. using 'PPO2':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines import PPO2\n",
    "model = PPO2(CustomPolicy, env,\n",
    "             gamma=gamma, learning_rate=learning_rate,\n",
    "             verbose=1, tensorboard_log=tensorboard_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=total_timesteps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
